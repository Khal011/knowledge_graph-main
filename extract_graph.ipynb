{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yo\n"
     ]
    }
   ],
   "source": [
    "print(\"yo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from langchain.document_loaders import PyPDFLoader, UnstructuredPDFLoader, PyPDFium2Loader\n",
    "from langchain.document_loaders import PyPDFDirectoryLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "## input data directory\n",
    "data_dir = \"cureus\"\n",
    "inputdirectory = Path(f\"./data_input/{data_dir}/\")\n",
    "## This is where the output csv files will be written\n",
    "out_dir = data_dir\n",
    "outputdirectory = Path(f\"./data_output/{out_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:06<00:00,  6.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks =  56\n",
      "Early diencephalon development in birds (chick) and mam- mals (humans) follows a similar pattern. Specifically, a single diencephalic compartment divides into two zones: the par- encephalon and synencephalon. Subsequently, the paren- cephalon becomes subdivided into an anterior and poste- rior unit. Some studies, including the present one, have\n",
      "\n",
      "Received: December 19, 2006\n",
      "\n",
      "Returned for revision: March 6, 2007\n",
      "\n",
      "Accepted after revision: May 9, 2007\n",
      "\n",
      "Published online: September 20, 2007\n",
      "\n",
      "M.B. Pritz\n",
      "\n",
      "Department of Neurological Surgery\n",
      "\n",
      "Indiana University School of Medicine, 545 Barnhill Drive, Emerson 141\n",
      "\n",
      "Indianapolis, IN 46202\n",
      "\n",
      "5124 (USA)\n",
      "\n",
      "Tel. +1 317 274 5728, Fax. +1 317 274 7351, E-Mail mpritz@iupui.edu\n",
      "\n",
      "© 200  S. Karger AG, Basel\n",
      "\n",
      "0006–8977/08/0711–0015$24.50/0\n",
      "\n",
      "Accessible online at:\n",
      "\n",
      "www.karger.com/bbe\n",
      "\n",
      "7\n",
      "\n",
      "Pritz\n",
      "\n",
      "Brain Behav Evol 2008;71:15–31 16 have questioned whether such a phylotypic stage exists for body plans in vertebrates [Richardson et al., 1997]. It remains to be seen whether or not such a phylotypic stage is present for developing vertebrate brains.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Dir PDF Loader\n",
    "# loader = PyPDFDirectoryLoader(inputdirectory)\n",
    "## File Loader\n",
    "# loader = PyPDFLoader(\"./data/MedicalDocuments/orf-path_health-n1.pdf\")\n",
    "loader = DirectoryLoader(inputdirectory, show_progress=True)\n",
    "documents = loader.load()\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1500,\n",
    "    chunk_overlap=150,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "\n",
    "pages = splitter.split_documents(documents)\n",
    "print(\"Number of chunks = \", len(pages))\n",
    "print(pages[3].page_content)\n",
    "# pages=pages[:1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dataframe of all the chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 3)\n",
      "                                                text  \\\n",
      "0  See discussions, stats, and author profiles fo...   \n",
      "1  Copyright  2007 S. Karger AG, Basel Introducti...   \n",
      "2  Key Words Alligator mississipiensis ! Developm...   \n",
      "3  Early diencephalon development in birds (chick...   \n",
      "4  Most developmental studies have focused on jus...   \n",
      "\n",
      "                                      source                          chunk_id  \n",
      "0  data_input\\cureus\\Dien.DevelopBBE2008.txt  b64a9052b7b54a8bac6f13bdeea4ccae  \n",
      "1  data_input\\cureus\\Dien.DevelopBBE2008.txt  3d8adf9ff2f44cc887e5df05bca6f5f8  \n",
      "2  data_input\\cureus\\Dien.DevelopBBE2008.txt  302e8070fe1d44a39a3f4a93b7a89957  \n",
      "3  data_input\\cureus\\Dien.DevelopBBE2008.txt  c388e84508424260a917b0d5f0a8d565  \n",
      "4  data_input\\cureus\\Dien.DevelopBBE2008.txt  369b3304c3784410a966b5fc1a8e03df  \n"
     ]
    }
   ],
   "source": [
    "from helpers.df_helpers import documents2Dataframe\n",
    "\n",
    "df = documents2Dataframe(pages)\n",
    "def clean_text(text):\n",
    "    # Replace newlines followed by letters with a space\n",
    "    if len(text) > 1:\n",
    "        cleaned_text = ''.join([text[i] if not (text[i] == '\\n' and text[i+1].isalnum()) else ' ' for i in range(len(text)-1)]) + text[-1]\n",
    "    else:\n",
    "        cleaned_text = text\n",
    "\n",
    "    # Remove remaining newlines\n",
    "    cleaned_text = cleaned_text.replace('\\n', ' ')\n",
    "\n",
    "    # Replace multiple spaces with a single space\n",
    "    cleaned_text = ' '.join(cleaned_text.split())\n",
    "\n",
    "    # Remove unwanted special characters\n",
    "    allowed_chars = set(\"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789 .,;:!?\\\"'()-\")\n",
    "    cleaned_text = ''.join([char for char in cleaned_text if char in allowed_chars])\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "# Apply the clean_text function to the 'content' column of the DataFrame\n",
    "df['text'] = df['text'].apply(clean_text)\n",
    "\n",
    "\n",
    "print(df.shape)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This function uses the helpers/prompt function to extract concepts from text\n",
    "from helpers.df_helpers import df2Graph\n",
    "from helpers.df_helpers import graph2Df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If regenerate is set to True then the dataframes are regenerated and Both the dataframes are written in the csv format so we dont have to calculate them again. \n",
    "\n",
    "        dfne = dataframe of edges\n",
    "\n",
    "        df = dataframe of chunks\n",
    "\n",
    "\n",
    "Else the dataframes are read from the output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"node_1\": \"Alligator\",\n",
      "        \"node_2\": \"Early Diencephalon Development\",\n",
      "        \"edge\": \"describes the development of\"\n",
      "    },\n",
      "    {\n",
      "        \"node_1\": \"Diencephalon\",\n",
      "        \"node_2\": \"Alligator\",\n",
      "        \"edge\": \"in the context of its early development\"\n",
      "    },\n",
      "    {\n",
      "        \"node_1\": \"Synencephalon\",\n",
      "        \"node_2\": \"Anterior and Posterior Component\",\n",
      "        \"edge\": \"is further parcellated into\"\n",
      "    },\n",
      "    {\n",
      "        \"node_1\": \"Reptiles\",\n",
      "        \"node_2\": \"Alligator\",\n",
      "        \"edge\": \"in the context of early diencephalon development\"\n",
      "    },\n",
      "    {\n",
      "        \"node_1\": \"Birds\",\n",
      "        \"node_2\": \"Chick\",\n",
      "        \"edge\": \"and mammals (humans) also exhibit similar patterns\"\n",
      "    },\n",
      "    {\n",
      "        \"node_1\": \"Amniotes\",\n",
      "        \"node_2\": \"Early Diencephalon Development\",\n",
      "        \"edge\": \"share a similar initial pattern of development\"\n",
      "    }\n",
      "][\n",
      "   {\n",
      "       \"node_1\": \"forebrain\",\n",
      "       \"node_2\": \"vertebrates"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m regenerate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m regenerate:\n\u001b[1;32m----> 5\u001b[0m     concepts_list \u001b[38;5;241m=\u001b[39m \u001b[43mdf2Graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mllama3:latest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     dfg1 \u001b[38;5;241m=\u001b[39m graph2Df(concepts_list)\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(outputdirectory):\n",
      "File \u001b[1;32mc:\\Users\\medkh\\Desktop\\Python\\knowledge_graph-main\\helpers\\df_helpers.py:52\u001b[0m, in \u001b[0;36mdf2Graph\u001b[1;34m(dataframe, model)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdf2Graph\u001b[39m(dataframe: pd\u001b[38;5;241m.\u001b[39mDataFrame, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;66;03m# dataframe.reset_index(inplace=True)\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mdataframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraphPrompt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchunk_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_id\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;66;03m# invalid json results in NaN\u001b[39;00m\n\u001b[0;32m     56\u001b[0m     results \u001b[38;5;241m=\u001b[39m results\u001b[38;5;241m.\u001b[39mdropna()\n",
      "File \u001b[1;32mc:\\Users\\medkh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:10374\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m  10360\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[0;32m  10362\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[0;32m  10363\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  10364\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10372\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m  10373\u001b[0m )\n\u001b[1;32m> 10374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\medkh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[0;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[1;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\medkh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[1;32mc:\\Users\\medkh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[0;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\medkh\\Desktop\\Python\\knowledge_graph-main\\helpers\\df_helpers.py:53\u001b[0m, in \u001b[0;36mdf2Graph.<locals>.<lambda>\u001b[1;34m(row)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdf2Graph\u001b[39m(dataframe: pd\u001b[38;5;241m.\u001b[39mDataFrame, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;66;03m# dataframe.reset_index(inplace=True)\u001b[39;00m\n\u001b[0;32m     52\u001b[0m     results \u001b[38;5;241m=\u001b[39m dataframe\u001b[38;5;241m.\u001b[39mapply(\n\u001b[1;32m---> 53\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m row: \u001b[43mgraphPrompt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchunk_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_id\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     54\u001b[0m     )\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;66;03m# invalid json results in NaN\u001b[39;00m\n\u001b[0;32m     56\u001b[0m     results \u001b[38;5;241m=\u001b[39m results\u001b[38;5;241m.\u001b[39mdropna()\n",
      "File \u001b[1;32mc:\\Users\\medkh\\Desktop\\Python\\knowledge_graph-main\\helpers\\prompts.py:74\u001b[0m, in \u001b[0;36mgraphPrompt\u001b[1;34m(input, metadata, model)\u001b[0m\n\u001b[0;32m     42\u001b[0m SYS_PROMPT \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are a network graph maker who extracts terms and their relations from a given context. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are provided with a context chunk (delimited by ```) Your task is to extract the ontology \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     69\u001b[0m )\n\u001b[0;32m     73\u001b[0m USER_PROMPT \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext: ```\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m``` \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m output: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 74\u001b[0m response, _ \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSYS_PROMPT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mUSER_PROMPT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m     result \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(response)\n",
      "File \u001b[1;32mc:\\Users\\medkh\\Desktop\\Python\\knowledge_graph-main\\ollama\\client.py:35\u001b[0m, in \u001b[0;36mgenerate\u001b[1;34m(model_name, prompt, system, template, context, options, callback)\u001b[0m\n\u001b[0;32m     32\u001b[0m full_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Iterating over the response line by line and displaying the details\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_lines\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Parsing each line (JSON chunk) and extracting the details\u001b[39;49;00m\n\u001b[0;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\medkh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\models.py:869\u001b[0m, in \u001b[0;36mResponse.iter_lines\u001b[1;34m(self, chunk_size, decode_unicode, delimiter)\u001b[0m\n\u001b[0;32m    860\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Iterates over the response data, one line at a time.  When\u001b[39;00m\n\u001b[0;32m    861\u001b[0m \u001b[38;5;124;03mstream=True is set on the request, this avoids reading the\u001b[39;00m\n\u001b[0;32m    862\u001b[0m \u001b[38;5;124;03mcontent at once into memory for large responses.\u001b[39;00m\n\u001b[0;32m    863\u001b[0m \n\u001b[0;32m    864\u001b[0m \u001b[38;5;124;03m.. note:: This method is not reentrant safe.\u001b[39;00m\n\u001b[0;32m    865\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    867\u001b[0m pending \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 869\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_unicode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_unicode\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    872\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpending\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[0;32m    873\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpending\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\medkh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\models.py:820\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[1;34m()\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    819\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 820\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    822\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[1;32mc:\\Users\\medkh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\response.py:1057\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;124;03mA generator wrapper for the read() method. A call will block until\u001b[39;00m\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;124;03m``amt`` bytes have been read from the connection or until the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1054\u001b[0m \u001b[38;5;124;03m    'content-encoding' header.\u001b[39;00m\n\u001b[0;32m   1055\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1056\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunked \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupports_chunked_reads():\n\u001b[1;32m-> 1057\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_chunked(amt, decode_content\u001b[38;5;241m=\u001b[39mdecode_content)\n\u001b[0;32m   1058\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1059\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\medkh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\response.py:1206\u001b[0m, in \u001b[0;36mHTTPResponse.read_chunked\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m   1203\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1205\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m-> 1206\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_chunk_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1207\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1208\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\medkh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\response.py:1125\u001b[0m, in \u001b[0;36mHTTPResponse._update_chunk_length\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1125\u001b[0m line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline()  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[0;32m   1126\u001b[0m line \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\medkh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## To regenerate the graph with LLM, set this to True\n",
    "regenerate = True\n",
    "\n",
    "if regenerate:\n",
    "    concepts_list = df2Graph(df, model=\"llama3:latest\")\n",
    "    dfg1 = graph2Df(concepts_list)\n",
    "    if not os.path.exists(outputdirectory):\n",
    "        os.makedirs(outputdirectory)\n",
    "    \n",
    "    dfg1.to_csv(outputdirectory/\"graph.csv\", sep=\"|\", index=False)\n",
    "    df.to_csv(outputdirectory/\"chunks.csv\", sep=\"|\", index=False)\n",
    "else:\n",
    "    dfg1 = pd.read_csv(outputdirectory/\"graph.csv\", sep=\"|\")\n",
    "\n",
    "dfg1.replace(\"\", np.nan, inplace=True)\n",
    "dfg1.dropna(subset=[\"node_1\", \"node_2\", 'edge'], inplace=True)\n",
    "dfg1['count'] = 4 \n",
    "## Increasing the weight of the relation to 4. \n",
    "## We will assign the weight of 1 when later the contextual proximity will be calculated.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating contextual proximity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def contextual_proximity(df: pd.DataFrame) -> pd.DataFrame:\n",
    "#     ## Melt the dataframe into a list of nodes\n",
    "#     dfg_long = pd.melt(\n",
    "#         df, id_vars=[\"chunk_id\"], value_vars=[\"node_1\", \"node_2\"], value_name=\"node\"\n",
    "#     )\n",
    "#     dfg_long.drop(columns=[\"variable\"], inplace=True)\n",
    "#     # Self join with chunk id as the key will create a link between terms occuring in the same text chunk.\n",
    "#     dfg_wide = pd.merge(dfg_long, dfg_long, on=\"chunk_id\", suffixes=(\"_1\", \"_2\"))\n",
    "#     # drop self loops\n",
    "#     self_loops_drop = dfg_wide[dfg_wide[\"node_1\"] == dfg_wide[\"node_2\"]].index\n",
    "#     dfg2 = dfg_wide.drop(index=self_loops_drop).reset_index(drop=True)\n",
    "#     ## Group and count edges.\n",
    "#     dfg2 = (\n",
    "#         dfg2.groupby([\"node_1\", \"node_2\"])\n",
    "#         .agg({\"chunk_id\": [\",\".join, \"count\"]})\n",
    "#         .reset_index()\n",
    "#     )\n",
    "#     dfg2.columns = [\"node_1\", \"node_2\", \"chunk_id\", \"count\"]\n",
    "#     dfg2.replace(\"\", np.nan, inplace=True)\n",
    "#     dfg2.dropna(subset=[\"node_1\", \"node_2\"], inplace=True)\n",
    "#     # Drop edges with 1 count\n",
    "#     dfg2 = dfg2[dfg2[\"count\"] != 1]\n",
    "#     dfg2[\"edge\"] = \"contextual proximity\"\n",
    "#     return dfg2\n",
    "\n",
    "\n",
    "# dfg2 = contextual_proximity(dfg1)\n",
    "# dfg2.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge both the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node_1</th>\n",
       "      <th>node_2</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>edge</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abbreviations used in figures</td>\n",
       "      <td>acetyl tub</td>\n",
       "      <td>a069c2b3bb334c1fb53930c7b5c37bf4</td>\n",
       "      <td>used for</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abbreviations used in figures</td>\n",
       "      <td>ache</td>\n",
       "      <td>a069c2b3bb334c1fb53930c7b5c37bf4</td>\n",
       "      <td>used for</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abbreviations used in figures</td>\n",
       "      <td>cv</td>\n",
       "      <td>a069c2b3bb334c1fb53930c7b5c37bf4</td>\n",
       "      <td>used for</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abbreviations used in figures</td>\n",
       "      <td>d</td>\n",
       "      <td>a069c2b3bb334c1fb53930c7b5c37bf4</td>\n",
       "      <td>used for</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>acetylated tubulin</td>\n",
       "      <td>diencephalon-mesencephalon border</td>\n",
       "      <td>513e045899fc4064bb3790bfa5458508</td>\n",
       "      <td>immunoreactivity positive</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>zona limitans interparencephalica</td>\n",
       "      <td>parencephalon</td>\n",
       "      <td>d94bb4a6b2e74ee4ad662a201f0b541b</td>\n",
       "      <td>separates into anterior and posterior divisions</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>zona limitans interparencephalica</td>\n",
       "      <td>parencephalon anterior</td>\n",
       "      <td>708c27f976ef4120bfa867226b6a49b7,831684506fb74...</td>\n",
       "      <td>A band, the zona limitans interparencephalica,...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>zona limitans interparencephalica</td>\n",
       "      <td>parencephalon posterior</td>\n",
       "      <td>831684506fb74052b859de9c36321584,03d83c94e7b44...</td>\n",
       "      <td>The zona limitans interparencephalica separate...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>zona limitans interparencephalica</td>\n",
       "      <td>zona limitans intrathalamica</td>\n",
       "      <td>f1fa2dacb94c413e906eca383de62bd2</td>\n",
       "      <td>might correspond to part or all of</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>zona limitans intrathalamica</td>\n",
       "      <td>anterior and posterior parts</td>\n",
       "      <td>5c21a9eddc714dc088a2916880749445</td>\n",
       "      <td>divided the parencephalon into these two parts</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>362 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                node_1                             node_2  \\\n",
       "0        abbreviations used in figures                         acetyl tub   \n",
       "1        abbreviations used in figures                               ache   \n",
       "2        abbreviations used in figures                                 cv   \n",
       "3        abbreviations used in figures                                  d   \n",
       "4                   acetylated tubulin  diencephalon-mesencephalon border   \n",
       "..                                 ...                                ...   \n",
       "357  zona limitans interparencephalica                      parencephalon   \n",
       "358  zona limitans interparencephalica             parencephalon anterior   \n",
       "359  zona limitans interparencephalica            parencephalon posterior   \n",
       "360  zona limitans interparencephalica       zona limitans intrathalamica   \n",
       "361       zona limitans intrathalamica       anterior and posterior parts   \n",
       "\n",
       "                                              chunk_id  \\\n",
       "0                     a069c2b3bb334c1fb53930c7b5c37bf4   \n",
       "1                     a069c2b3bb334c1fb53930c7b5c37bf4   \n",
       "2                     a069c2b3bb334c1fb53930c7b5c37bf4   \n",
       "3                     a069c2b3bb334c1fb53930c7b5c37bf4   \n",
       "4                     513e045899fc4064bb3790bfa5458508   \n",
       "..                                                 ...   \n",
       "357                   d94bb4a6b2e74ee4ad662a201f0b541b   \n",
       "358  708c27f976ef4120bfa867226b6a49b7,831684506fb74...   \n",
       "359  831684506fb74052b859de9c36321584,03d83c94e7b44...   \n",
       "360                   f1fa2dacb94c413e906eca383de62bd2   \n",
       "361                   5c21a9eddc714dc088a2916880749445   \n",
       "\n",
       "                                                  edge  count  \n",
       "0                                             used for      4  \n",
       "1                                             used for      4  \n",
       "2                                             used for      4  \n",
       "3                                             used for      4  \n",
       "4                            immunoreactivity positive      4  \n",
       "..                                                 ...    ...  \n",
       "357    separates into anterior and posterior divisions      4  \n",
       "358  A band, the zona limitans interparencephalica,...     12  \n",
       "359  The zona limitans interparencephalica separate...      8  \n",
       "360                 might correspond to part or all of      4  \n",
       "361     divided the parencephalon into these two parts      4  \n",
       "\n",
       "[362 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dfg = pd.concat([dfg1, dfg2], axis=0)\n",
    "dfg=dfg1\n",
    "dfg = (\n",
    "    dfg.groupby([\"node_1\", \"node_2\"])\n",
    "    .agg({\"chunk_id\": \",\".join, \"edge\": ','.join, 'count': 'sum'})\n",
    "    .reset_index()\n",
    ")\n",
    "dfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the NetworkX Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(433,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes = pd.concat([dfg['node_1'], dfg['node_2']], axis=0).unique()\n",
    "nodes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "G = nx.Graph()\n",
    "\n",
    "## Add nodes to the graph\n",
    "for node in nodes:\n",
    "    G.add_node(\n",
    "        str(node)\n",
    "    )\n",
    "\n",
    "## Add edges to the graph\n",
    "for index, row in dfg.iterrows():\n",
    "    G.add_edge(\n",
    "        str(row[\"node_1\"]),\n",
    "        str(row[\"node_2\"]),\n",
    "        title=row[\"edge\"],\n",
    "        weight=row['count']/4\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate communities for coloring the nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Communities =  114\n",
      "[[\"'-tubulin\", 'micro-tubules'], ['abbreviations used in figures', 'acetyl tub', 'ache', 'cv', 'd'], ['acetylated tubulin', 'calretinin', 'cells', 'diencephalon-mesencephalon border', 'longitudinal fibers', 'microtubules'], ['acetylated tubulin immunoreactivity', 'longitudinal division'], ['acetylcholine-positive neuroblasts', 'alligator', 'alligator mississipiensis', 'american alligator', 'amniotes', 'avian', 'bat', 'behav evol', 'brain', 'brains', 'cell proliferation', 'chick vaage, 1969', 'compartment development', 'd1and d2', 'd2 compartment mller and orahilly, 1997', 'developing diencephalon', 'development', 'developmentally significant criteria', 'diencephalic development', 'diencephalic segmentation', 'diencephalic subdivisions', 'diencephalon', 'diencephalon development', 'division', 'dlx-1', 'dlx-2', 'dorso-ventral axes', 'dorsoventral', 'early diencephalon development in alligator', 'early stages of development', 'events', 'evol', 'evolution', 'experiments', 'features', 'ferguson', 'forebrain', 'free floating sections', 'gbx-2', 'gelatin', 'hamster', 'histochemistry and immunocytochemistry', 'human embryos', 'humans', 'humans (mller and orahilly, 1997)', 'humans mller and orahilly, 1997', 'hyrax', 'isthmus', 'lamprey', 'larsen et al., 2001', 'lineage restrictions', 'lizard', 'lunatic fringe', 'mammal', 'mammals', 'markers', 'medaka', 'mller and orahilly', 'molecularly distinct transverse regions', 'morphological techniques', 'mouse', 'neuromeres', 'obser-vations', 'ontogeny', 'opossum', 'organization', 'pattern of development', 'patterning', 'pretectum', 'pritz', 'prosomeres', 'puelles et al., 1987', 'reptiles', 'rhesus monkey', 'rosto-caudal axes', 'rostrocaudal', 'sea turtle', 'secondary prosencephalic subdivisions', 'segmental organization', 'single compartment', 'snake', 'syn-encephalon', 'table 1', 'tissue', 'transverse subdivisions', 'transverse zones', 'vertebrates', 'washed', 'wnt-3'], ['acetylcholinesterase', 'glia or cells'], ['acquisition of boundary specific phenotype', 'cell lineage restriction'], ['additional markers', 'anlage for pretectum', 'anterior', 'anterior and posterior component', 'anterior and posterior parts', 'anterior and posterior portion', 'anterior compartment', 'anterior parencephalon', 'anterior segment', 'anterior subdivisions', 'anterior unit', 'anterior zones', 'border', 'calretinin immunoreactive', 'cephalon', 'diencephalic compartment', 'dorsal thalamus and epithalamus or thalamus', 'hypothalamus', 'mesencephalon', 'par-encephalon', 'parencephalon', 'parencephalon anterior', 'parencephalon anterior (d1)', 'parencephalon posterior', 'parencephalon posterior (d2)', 'posterior', 'posterior compartment', 'posterior portion', 'posterior segment', 'posterior unit', 'posterior zones', 'pretectum anterior and pretectum posterior', 'secondary prosencephalon', 'subdivisions', 'synencephalon', 't', 'telencephalon', 'ventral parencephalon', 'ventral thalamus or prethalamus', 'zona limitans interparencephalica', 'zona limitans intrathalamica'], ['adobe photoshop 7.0', 'photos'], ['adult diencephalons', 'alligator diencephalon'], ['aggregates', 'neuronal cell types'], ['alar parencephalon posterior', 'other alar territories'], ['alar parts', 'basal parts'], ['alar plate', 'basal plate', 'components', 'presumptive alar', 'presumptive alar plate', 'presumptive basal plate region'], ['alar plate regions', 'diencephalic segments', 'early dien-c cephalon development', 'fiber tracts', 'four segment stage'], ['alligator brain', 'sagittal and horizontal planes of sections'], ['alligator diencephalon development', 'antibodies', 'compartment', 'histochemical markers', 'monoclonal mouse anti-acetylated tubulin', 'monoclonal mouse anti-glial fibrillary acid protein (gfap)', 'monoclonal mouse anti-growth-associated protein 43 (gap 43)', 'monoclonal mouse anti-neural cell adhesion molecule (n-cam)', 'mouse monoclonal anti-acetylcholinesterase', 'mouse monoclonal anti-vimentin', 'polyclonal rabbit anti-calretinin'], ['alligator eggs', 'rockefeller wildlife refuge'], ['alligator pritz, 1999', 'early hindbrain development'], ['alligator study', 'chick (vaage, 1969)'], ['amphibians', 'newt'], ['animal care committee', 'national institute of health guidelines', 'procedures and protocols'], ['anti-neural cell adhesion molecule', 'diencephalic borders'], ['apical location', 'rhombomere borders'], ['approach', 'morphological observations', 'other vertebrates', 'prosomeric model'], ['barriers to cell mixing', 'borders', 'forebrain compartments', 'neuromere(s)', 'regulatory genes'], ['bird', 'birds', 'birds (chick)', 'chick', 'crocodiles', 'crocodilians', 'early diencephalon development', 'egg age', 'embryo', 'fixed and partly sectioned material', 'forebrain divisions', 'hamburger', 'hamburger and hamilton', 'hamilton', 'larsen et al.', 'living embryos', 'mammals (humans)', 'molecules', 'present study', 'puelles et al.', 'reproduction', 'reptilian', 'single segment stage', 'stage', 'studies', 'two segment stage', 'vaage', 'wax reconstructions'], ['black and white photos', 'color images'], ['blocks', 'pbs (0.1 m at ph 7.2)', 'sucrose'], ['boundary formation', 'compartition'], ['boundary formation and compartition in the avian diencephalon', 'larsen cw'], ['brain growth during development', 'plane of section', 'sagittal and horizontal planes', 'study'], ['bright field illumination', 'histological analysis process'], ['calretinin immunoreactivity', 'dorsoventral division'], ['camera lucida drawing tube', 'leitz microscope'], ['cell', 'culture'], ['cellular behavior', 'injury to embryonic donor tissue'], ['central nervous system', 'early histogenesis', 'morphogenesis', 'vertebrate'], ['chick counterparts', 'diencephalic neuromeres'], ['chick embryos', 'neural tube segmentation'], ['chick stages', 'hours'], ['compartments', 'segmental pattern'], ['compartments and their boundaries in vertebrate brain de- velopment', 'hedgehog signalling from the zli regulates diencephalic re- gional identity', 'kiecker c'], ['controls for nonspecific staining', 'omission of the primary antibody from the reaction', 'substitution of normal rabbit or mouse serum'], ['cortical function', 'thalamus'], ['cresyl violet', 'fixatives', 'histo-chemical preparations', 'histochemical and immunocytochemical experiments', 'material', 'morphological stains', 'peanut agglutinin'], ['dab solution', 'incubation', 'reaction'], ['day 12.5', 'stage 11.5'], ['develop-mentally significant criteria', 'keynes and lumsden (1990)'], ['developing chick hindbrain', 'hindbrain', 'rhombomeres', 'segmentation'], ['development of the dien- cephalon of the chinese hamster', 'keyser a'], ['developmental significance', 'neuromere'], ['diencephalic divisions', 'histochemical stain', 'three segment stage'], ['diencephalon patterning', 'hedgehog signalling'], ['different adult diencephalons', 'molecular events'], ['digital camera', 'olympus microscope'], ['division into anterior and posterior components', \"others' experimental data\"], ['divisions of the diencephalon', 'morpho-logic features'], ['dorsal diencephalon', 'shh', 'zli'], ['early diencephalon development in chick and humans', 'present observations', 'purely morphological data'], ['eggs', 'vermiculite and water'], ['embryology', 'zwischenhirn'], ['embryos', 'stages', 'tissues'], ['experiment', 'immunocytochemical'], ['figdor and stern 1993', 'larsen et al. 2001'], ['freez- ing', 'tissue preservation'], ['gene expression', 'morphology'], ['gene expression mapping', 'influence'], ['gene expression patterns', 'transverse regions'], ['gene or transcription factor expression', 'individual units'], ['grafts', 'size limitation'], ['gribnau aa', 'morphogen-esis of the brain'], ['hamburger v', 'normal stages in the development of the chick embryo'], ['hedges sb', 'molecular evidence for the origin of birds'], ['histological staining', 'techniques'], ['hrp-peanut lectin', 'incubated'], ['identification', 'transversal diencephalic subdivisions'], ['images', 'panels'], ['interneuromeric ventricular ridges', 'neuromeric bulges'], ['journal', 'pritz brain behav evol'], ['kage t', 'morphogenesis and regionalization of the medaka embry- onic brain'], ['keynes', 'lumsden'], ['keynes r', 'segmentation and the origin of regional diversity in the vertebrate central nervous system'], ['kumar s', 'molecular time-scale for vertebrate evolution'], ['lampreys', 'sea lamprey'], ['lateral photo', 'sagittal plane', 'stage 12 brain'], ['marine ray', 'sharkrays'], ['martin ld', 'whetstone kn'], ['mes-encephalon', 'synencephalon posterior'], ['methodology', 'peanut agglutinin histochemistry'], ['migration areas', 'vertebrate central tube'], ['mller', 'orahilly'], ['most studies', 'single division'], ['mounted', 'slides'], ['mounting', 'sections', 'transferred'], ['nature', 'origin of birds and crocodiles'], ['neural precursor cells', 'neurofilament proteins'], [\"others' observations\", 'selection of markers'], ['p', 'prosencephalon'], ['pap complex', 'primary antibody', 'secondary antibody'], ['peanut agglutinin stained sections', 'thickness of the most lateral portion of the positively stained diencephalic mantle layer'], ['pial surface', 'ventricular surface'], ['presumed alar and basal plate', 'transverse diencephalic segments'], ['prosomere 1 (synencephalon)', 'prosomere 2 (parencephalon posteri- or)', 'prosomere 3 (parencephalon anterior)', 'territory'], ['prosomeric domains', 'zebrafish forebrain'], ['puelles and rubenstein, 2003', 'reference'], ['radial glia', 'vimentin'], ['respective borders', 'transverse dience- phalic zones'], ['separate compartment', 'this region'], ['single segment', 'transverse plane'], ['species', 'temperature'], ['synencephalon anterior (d3)', 'synencephalon posterior (d4)'], ['teleosts', 'zebrafish'], ['tissue sectioned transversally', 'zona limi- tans interparencephalica']]\n"
     ]
    }
   ],
   "source": [
    "communities_generator = nx.community.girvan_newman(G)\n",
    "top_level_communities = next(communities_generator)\n",
    "next_level_communities = next(communities_generator)\n",
    "communities = sorted(map(sorted, next_level_communities))\n",
    "print(\"Number of Communities = \", len(communities))\n",
    "print(communities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataframe for community colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node</th>\n",
       "      <th>color</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'-tubulin</td>\n",
       "      <td>#db57d3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>micro-tubules</td>\n",
       "      <td>#db57d3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abbreviations used in figures</td>\n",
       "      <td>#dbb957</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>acetyl tub</td>\n",
       "      <td>#dbb957</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ache</td>\n",
       "      <td>#dbb957</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>synencephalon posterior (d4)</td>\n",
       "      <td>#dbd557</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>teleosts</td>\n",
       "      <td>#57db90</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>zebrafish</td>\n",
       "      <td>#57db90</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>tissue sectioned transversally</td>\n",
       "      <td>#db57b7</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>zona limi- tans interparencephalica</td>\n",
       "      <td>#db57b7</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>433 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    node    color  group\n",
       "0                              '-tubulin  #db57d3      1\n",
       "1                          micro-tubules  #db57d3      1\n",
       "2          abbreviations used in figures  #dbb957      2\n",
       "3                             acetyl tub  #dbb957      2\n",
       "4                                   ache  #dbb957      2\n",
       "..                                   ...      ...    ...\n",
       "428         synencephalon posterior (d4)  #dbd557    112\n",
       "429                             teleosts  #57db90    113\n",
       "430                            zebrafish  #57db90    113\n",
       "431       tissue sectioned transversally  #db57b7    114\n",
       "432  zona limi- tans interparencephalica  #db57b7    114\n",
       "\n",
       "[433 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "palette = \"hls\"\n",
    "\n",
    "## Now add these colors to communities and make another dataframe\n",
    "def colors2Community(communities) -> pd.DataFrame:\n",
    "    ## Define a color palette\n",
    "    p = sns.color_palette(palette, len(communities)).as_hex()\n",
    "    random.shuffle(p)\n",
    "    rows = []\n",
    "    group = 0\n",
    "    for community in communities:\n",
    "        color = p.pop()\n",
    "        group += 1\n",
    "        for node in community:\n",
    "            rows += [{\"node\": node, \"color\": color, \"group\": group}]\n",
    "    df_colors = pd.DataFrame(rows)\n",
    "    return df_colors\n",
    "\n",
    "\n",
    "colors = colors2Community(communities)\n",
    "colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add colors to the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in colors.iterrows():\n",
    "    G.nodes[row['node']]['group'] = row['group']\n",
    "    G.nodes[row['node']]['color'] = row['color']\n",
    "    G.nodes[row['node']]['size'] = G.degree[row['node']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyvis.network import Network\n",
    "import webbrowser\n",
    "\n",
    "graph_output_directory = \"./docs/index.html\"\n",
    "\n",
    "net = Network(\n",
    "    notebook=False,\n",
    "    cdn_resources=\"remote\",\n",
    "    height=\"900px\",\n",
    "    width=\"100%\",\n",
    "    select_menu=True,\n",
    "    filter_menu=False,\n",
    ")\n",
    "\n",
    "# Assuming G is your networkx graph\n",
    "net.from_nx(G)\n",
    "net.force_atlas_2based(central_gravity=0.015, gravity=-31)\n",
    "net.show_buttons(filter_=[\"physics\"])\n",
    "\n",
    "# Generate HTML content\n",
    "html_content = net.generate_html()\n",
    "\n",
    "# Write the HTML content with UTF-8 encoding\n",
    "with open(graph_output_directory, 'w', encoding='utf-8') as file:\n",
    "    file.write(html_content)\n",
    "\n",
    "# Optionally open the file in the browser\n",
    "webbrowser.open(graph_output_directory)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
